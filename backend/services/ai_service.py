# backend/services/ai_service.py
import google.generativeai as genai
import json
import requests

class AIService:
    def __init__(self):
        pass

    def get_available_models(self, api_key: str) -> list:
       """
       åˆ—å‡ºè©² API Key å¯ç”¨çš„æ‰€æœ‰ç”Ÿæˆå¼æ¨¡å‹
       """
       try:
           genai.configure(api_key=api_key)
           model_list = []
           for m in genai.list_models():
               # åªåˆ—å‡ºæ”¯æ´ 'generateContent' (æ–‡å­—ç”Ÿæˆ) çš„æ¨¡å‹
               if 'generateContent' in m.supported_generation_methods:
                   model_list.append(m.name)
           
           # æ’åºä¸€ä¸‹ï¼Œæ¯”è¼ƒå¥½æ‰¾
           return sorted(model_list)
       except Exception as e:
           # å¦‚æœ API Key éŒ¯èª¤æˆ–é€£ç·šå¤±æ•—ï¼Œå›å‚³ç©ºé™£åˆ—æˆ–é è¨­å€¼
           print(f"Fetch models error: {e}")
           return []

    def get_analysis(self, api_key: str, stock_id: str, mode: str, cost: float, context_data: str, model_name: str):
        """
        å‘¼å« Gemini API é€²è¡Œåˆ†æ
        """
        try:
            genai.configure(api_key=api_key)
            
            # è‡ªå‹•é¸æ“‡æ¨¡å‹é‚è¼¯
            model = genai.GenerativeModel(model_name)
            
            # å¦‚æœè¦æ›´åš´è¬¹å¯ä»¥åŠ å…¥åŸæœ¬çš„ find_best_model é‚è¼¯ï¼Œé€™è£¡ç°¡åŒ–ç›´æ¥æŒ‡å®š
            model = genai.GenerativeModel(model_name)

            prompt = f"""
            ä½ æ˜¯ä¸€ä½è³‡æ·±å°è‚¡æ“ç›¤æ‰‹ï¼Œä¸¦ä¸”èƒ½å¤ æä¾›æ˜ç¢ºä¸”æœæ–·çš„åˆ¤æ–·ã€‚è«‹åˆ†æä»¥ä¸‹è‚¡ç¥¨æ•¸æ“šã€‚
            åƒæ•¸: ä»£è™Ÿ {stock_id}, æ–¹å‘ {mode}, æˆæœ¬ {cost}
            æ•¸æ“š: {context_data}
            
            ä»»å‹™:
            1. çµ¦å‡ºæ˜ç¢ºæ“ä½œå»ºè­° (è²·é€²/è³£å‡º/çºŒæŠ±/æ­¢æ)ã€‚
            2. æŒ‡å‡ºé—œéµæ”¯æ’èˆ‡å£“åŠ›åƒ¹ä½ã€‚
            3. ä½¿ç”¨æ¢åˆ—å¼ï¼Œå£èªåŒ–ï¼Œ500å­—å…§ã€‚
            4. æ˜¯å¦é©åˆä½œç‚ºéš”æ—¥æ²–çš„æ¨™çš„ã€‚
            5. æ ¹æ“šåˆ†æçµæœçµ¦å‡º (1) é€²å ´åƒ¹æ ¼ (2) åœåˆ©åƒ¹æ ¼ (3) åœæåƒ¹æ ¼
            """
            
            response = model.generate_content(prompt)
            return response.text
            
        except Exception as e:
            return f"AI åˆ†æå¤±æ•—: {str(e)}"
        
    def get_trade_signal(self, api_key: str, stock_id: str, context_data: str, provider: str = "gemini", model_name: str = "gemini-1.5-flash"):
        """
        æ ¹æ“š provider æ±ºå®šå‘¼å« Gemini é‚„æ˜¯ Ollama
        """
        # å®šç¾© Prompt (å…±ç”¨)
        system_prompt = f"""
        ä½ æ˜¯ä¸€å€‹é‡åŒ–äº¤æ˜“æ±ºç­–ç³»çµ±ã€‚è«‹æ ¹æ“šæä¾›çš„è‚¡ç¥¨æ•¸æ“šé€²è¡Œåˆ†æã€‚
        è‚¡ç¥¨ä»£è™Ÿ: {stock_id}
        æ•¸æ“šæ‘˜è¦: {context_data}

        ä»»å‹™ï¼š
        1. åˆ¤æ–·æ˜¯å¦é©åˆé€²å ´ï¼ˆåšå¤š Long æˆ– è§€æœ› Holdï¼‰ã€‚
        2. å¦‚æœåšå¤šï¼Œçµ¦å‡ºæ˜ç¢ºçš„é€²å ´åƒ¹ã€åœæåƒ¹ã€åœåˆ©åƒ¹ã€‚
        3. åš´æ ¼è¼¸å‡º JSON æ ¼å¼ï¼Œä¸è¦åŒ…å« Markdown æ¨™è¨˜ã€‚

        JSON æ ¼å¼ç¯„ä¾‹ï¼š
        {{
            "action": "BUY", 
            "entry_price": 100.5,
            "stop_loss": 95.0,
            "take_profit": 110.0,
            "reason": "çªç ´å‡ç·šç³¾çµ"
        }}
        """

        if provider == "ollama":
            return self._call_ollama(model_name, system_prompt)
        else:
            return self._call_gemini(api_key, model_name, system_prompt)

    def _call_gemini(self, api_key, model_name, prompt):
        try:
            if not api_key:
                return {"action": "HOLD", "reason": "æœªæä¾› Gemini API Key"}
                
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel(model_name)
            
            # åŠ ä¸Š JSON mode æç¤ºæ¯”è¼ƒä¿éšª
            response = model.generate_content(prompt + "\nè«‹ç¢ºä¿åªå›å‚³ JSON å­—ä¸²ã€‚")
            text = response.text.strip()
            
            # æ¸…ç† markdown
            if text.startswith("```json"):
                text = text[7:]
            if text.endswith("```"):
                text = text[:-3]
            
            return json.loads(text)
        except Exception as e:
            print(f"Gemini Error: {e}")
            return {"action": "HOLD", "reason": f"Gemini éŒ¯èª¤: {str(e)}"}

    def _call_ollama(self, model_name, prompt):
        """
        å‘¼å«æœ¬åœ° Ollama API (é è¨­ port 11434)
        """
        try:
            url = "http://localhost:11434/api/chat"
            payload = {
                "model": model_name,
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "stream": False,
                "format": "json" # Ollama æ”¯æ´å¼·åˆ¶ JSON æ¨¡å¼ (éœ€è¼ƒæ–°ç‰ˆæœ¬)
            }
            
            response = requests.post(url, json=payload, timeout=120)
            
            if response.status_code == 200:
                result = response.json()
                content = result.get("message", {}).get("content", "{}")
                print(f"ğŸ¤– AI Raw Response: {content}") 
                return json.loads(content)
            else:
                return {"action": "HOLD", "reason": f"Ollama HTTP {response.status_code}"}
                
        except Exception as e:
            print(f"Ollama Error: {e}")
            return {"action": "HOLD", "reason": "Ollama é€£ç·šå¤±æ•—ï¼Œè«‹ç¢ºèªæ˜¯å¦å·²å•Ÿå‹• (ollama serve)"}